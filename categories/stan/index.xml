<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stan on p( ssp3nc3r | Columbian )</title>
    <link>https://ssp3nc3r.github.io/categories/stan/</link>
    <description>Recent content in Stan on p( ssp3nc3r | Columbian )</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 04 Oct 2024 23:54:42 -0400</lastBuildDate>
    <atom:link href="https://ssp3nc3r.github.io/categories/stan/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lost in the forest</title>
      <link>https://ssp3nc3r.github.io/post/lost-in-the-forest/</link>
      <pubDate>Fri, 04 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://ssp3nc3r.github.io/post/lost-in-the-forest/</guid>
      <description>&lt;p&gt;In this post, I want to address why Bayesian modeling approaches, especially those implemented in Stan, should be considered as a valid alternative to common machine learning techniques in sports analytics. Specifically, I’ll focus on a well-established criterion for model evaluation: leave-one-out cross-validation (LOO-CV) and its use to calculate the expected log predictive density (ELPD). This scoring rule measures how well a model predicts unseen data. If you’d like a deeper explanation of ELPD and its interpretation in the context of this example, I’ll include one in an appendix at the end.&lt;/p&gt;</description>
    </item>
    <item>
      <title>New online Stan coding course</title>
      <link>https://ssp3nc3r.github.io/post/new-online-stan-coding-course/</link>
      <pubDate>Mon, 17 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://ssp3nc3r.github.io/post/new-online-stan-coding-course/</guid>
      <description>&lt;p&gt;Hey everyone! I’m excited to announce my new online course for learning&#xA;direct Stan coding for Bayesian analysis. Available now; enroll here:&#xA;&lt;a href=&#34;https://athlyticz.com/stan-i&#34; class=&#34;uri&#34;&gt;https://athlyticz.com/stan-i&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;smallcaps&#34;&gt;— &lt;strong&gt;TL;DR&lt;/strong&gt; —&lt;/span&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Actual Stan coding, not a high-level interface&lt;/li&gt;&#xA;&lt;li&gt;At-your-own-pace videos: shows live coding while explaining&lt;/li&gt;&#xA;&lt;li&gt;Hosted RStudio session to practice alongside me&lt;/li&gt;&#xA;&lt;li&gt;Starts with fundamentals, builds to hierarchical models&lt;/li&gt;&#xA;&lt;li&gt;Emphasizes a Bayesian workflow&lt;/li&gt;&#xA;&lt;li&gt;Modeling applied to sports data&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;My goal is to &lt;strong&gt;make learning Stan as easy and fast as possible&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Speedy splines part two, derivative work</title>
      <link>https://ssp3nc3r.github.io/post/derivative-work-on-speedy-splines/</link>
      <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://ssp3nc3r.github.io/post/derivative-work-on-speedy-splines/</guid>
      <description>&lt;p&gt;In the last post, I showed how we can speed up computation for splines in Stan. This post is, ahem, derivative. Perhaps we have noisy data of position and time, and we want to estimate speed and acceleration. We can use b-splines and their derivatives for this.&lt;/p&gt;&#xA;&lt;p&gt;So let’s pick up where we left off, and add calculations in Stan to calculate the first and second derivatives of the spline in Stan. Much of the code below mirrors that of the previous post. There are multiple approaches to calculating derivatives of splines. We can take the derivative of the basis functions &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-rogers2001&#34;&gt;Rogers 2001, sec. 3.10&lt;/a&gt; B-Spline Curve Derivatives)&lt;/span&gt; or we can difference the coefficients &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-deboor2001&#34;&gt;Boor 2001&lt;/a&gt;, X. The Stable Evaluation of B-Splines and Splines)&lt;/span&gt;. In the Stan functions block below, I’ve added calculations for the first and second derivatives of the basis functions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Speedy splines in Stan part one</title>
      <link>https://ssp3nc3r.github.io/post/speedy-splines-in-stan/</link>
      <pubDate>Wed, 16 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://ssp3nc3r.github.io/post/speedy-splines-in-stan/</guid>
      <description>&lt;p&gt;Milad Kharratzadeh provides a helpful &lt;a href=&#34;https://mc-stan.org/users/documentation/case-studies/splines_in_stan.html&#34;&gt;case study&lt;/a&gt; on estimating splines in Stan. We can improve on his work with a few tricks to speed up the estimation process. Namely, if we decompose the spline matrix using QR decomposition, we speed up Stan’s fitting process by at least an order of magnitude.&lt;/p&gt;&#xA;&lt;p&gt;Here’s how we can alter the code to accommodate splines with a few tricks to speed things up:&lt;/p&gt;&#xA;&lt;pre class=&#34;stan&#34;&gt;&lt;code&gt;&#xA;functions {&#xA;  &#xA;  vector build_b_spline(vector t, array[] real ext_knots, int ind, int order) {&#xA;    &#xA;    vector[size(t)] b_spline;&#xA;    vector[size(t)] w1 = rep_vector(0, size(t));&#xA;    vector[size(t)] w2 = rep_vector(0, size(t));&#xA;    &#xA;    if (order == 1)&#xA;    &#xA;      for (i in 1:size(t)) &#xA;        b_spline[i] = (ext_knots[ind] &amp;lt;= t[i]) &amp;amp;&amp;amp; (t[i] &amp;lt; ext_knots[ind+1]); &#xA;    &#xA;    else {&#xA;    &#xA;      if (ext_knots[ind] != ext_knots[ind + order-1])&#xA;        w1 = (t - rep_vector(ext_knots[ind], size(t))) / &#xA;             (ext_knots[ind + order-1] - ext_knots[ind]);&#xA;      if (ext_knots[ind + 1] != ext_knots[ind + order])&#xA;        w2 = 1 - (t - rep_vector(ext_knots[ind + 1], size(t))) / &#xA;                 (ext_knots[ind + order] - ext_knots[ind + 1]);&#xA;                 &#xA;      b_spline = w1 .* build_b_spline(t, ext_knots, ind, order - 1) + &#xA;                 w2 .* build_b_spline(t, ext_knots, ind+1, order - 1);&#xA;    &#xA;    }&#xA;    &#xA;    return b_spline;&#xA;  &#xA;  }&#xA;  &#xA;}&#xA;&#xA;&#xA;data {&#xA;  &#xA;  int&amp;lt;lower=1&amp;gt; T;                 // number of times measured&#xA;  vector[T] t;                    // remove and replace with position&#xA;  vector[T] y;                    // the measurement at each time point t&#xA;  &#xA;  int&amp;lt;lower=1&amp;gt; K;                 // number of knots&#xA;  int&amp;lt;lower=1&amp;gt; degree;            // degree of the spline&#xA;  int&amp;lt;lower=0,upper=1&amp;gt; penalized; // whether to use prior for smoothing&#xA;  &#xA;}&#xA;&#xA;&#xA;transformed data {&#xA;  &#xA;  // knots at evenly-spaced quantiles of data&#xA;  array[K] real p;&#xA;  for(i in 1:K) p[i] = (i - 1.0) / (K-1.0);&#xA;  array[K] real k = quantile(t, p);&#xA;  &#xA;  // build the spline matrix B&#xA;  int n_basis = K + degree - 1; &#xA;  matrix[n_basis, T] B;&#xA;  &#xA;  array[2 * degree + K] real ext_knots =&#xA;  append_array(append_array(rep_array(k[1], degree), k), rep_array(k[K], degree));&#xA;  &#xA;  for (ind in 1:n_basis)&#xA;    B[ind,:] = to_row_vector(build_b_spline(t, (ext_knots), ind, degree + 1));&#xA;  &#xA;  B[K + degree - 1, T] = 1;&#xA;  &#xA;  // QR decomposition of B, thin and scale&#xA;  matrix[T, n_basis] Q_ast = qr_thin_Q(B&amp;#39;) * sqrt(T - 1);&#xA;  matrix[n_basis, n_basis] R_ast = qr_thin_R(B&amp;#39;) / sqrt(T - 1);&#xA;  matrix[n_basis, n_basis] R_ast_inverse = inverse(R_ast);&#xA;  &#xA;  // helper stuff&#xA;  vector[T] zeros_T = rep_vector(0, T);&#xA;  &#xA;}&#xA;&#xA;&#xA;parameters {&#xA;  &#xA;  vector[n_basis] theta_raw; // coefficients on Q_ast&#xA;  real&amp;lt;lower=0&amp;gt; sigma;       // scale of the variation&#xA;  real&amp;lt;lower=0&amp;gt; tau;         // penalization on wiggles&#xA;  &#xA;}&#xA;&#xA;&#xA;transformed parameters {&#xA;  &#xA;  vector[n_basis] theta;&#xA;  &#xA;  if(penalized) {&#xA;    theta[1] = theta_raw[1];&#xA;    for(i in 2:n_basis) theta[i] = theta[i-1] + theta_raw[i] * tau;&#xA;  } else {&#xA;    theta = theta_raw;&#xA;  }&#xA;  &#xA;}&#xA;&#xA;&#xA;model {&#xA;  &#xA;  theta_raw ~ normal(0, 1);&#xA;  tau ~ normal(0, 1);&#xA;  sigma ~ exponential(1);  &#xA;  y ~ normal_id_glm(Q_ast, zeros_T, theta, sigma);&#xA;&#xA;}&#xA;&#xA;generated quantities {&#xA;  vector[n_basis] beta;&#xA;  beta = R_ast_inverse * theta;&#xA;  vector[T] y_hat = B&amp;#39; * beta;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;We can compile the model like so,&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pitch selection to maximize motion-in-depth variation</title>
      <link>https://ssp3nc3r.github.io/post/pitch-selection-to-maximize-motion-in-depth/</link>
      <pubDate>Wed, 29 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://ssp3nc3r.github.io/post/pitch-selection-to-maximize-motion-in-depth/</guid>
      <description>&lt;p&gt;Those in baseball are well aware of the concept of platoon advantage: batters tend to have an advantage when facing pitchers of the opposite handedness. But knowledge of a platoon advantage may go beyond choice of relief pitchers on the mound to matchup with the upcoming lineup of power batters. It may inform, among other things, pitching strategy.&lt;/p&gt;&#xA;&lt;p&gt;Considering reasons behind the phenomenon, it may be explained by the greater relative variation in movement of the ball inside a batter’s &lt;strong&gt;plane of sight&lt;/strong&gt;, which I’ll define in a moment, while same-handed pitchers tend to keep the ball’s trajectory more aligned with that plane, making it harder to perceive lateral movement.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dynamic, physics-informed systems in Bayesian models</title>
      <link>https://ssp3nc3r.github.io/post/dynamic-systems-in-bayesian-models/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://ssp3nc3r.github.io/post/dynamic-systems-in-bayesian-models/</guid>
      <description>&lt;p&gt;By dynamic systems, I mean using differential equations to describe how data changes over time. Take running speed, for example. Several physics-based models of running speed have been developed, which I’ve previously discussed. The primary goal in those previous discussions involving sprint speed have been in estimating a maximum speed. But the underlying structure of these models estimate change in speed at time two from speed at time one: a differential equation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stan Is Not an Acronym: Bayesian Solutions to Sabermetric Shortcomings</title>
      <link>https://ssp3nc3r.github.io/post/stan-is-not-an-acronym-bayesian-solutions-to-sabermetric-shortcomings/</link>
      <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://ssp3nc3r.github.io/post/stan-is-not-an-acronym-bayesian-solutions-to-sabermetric-shortcomings/</guid>
      <description>&lt;script src=&#34;https://ssp3nc3r.github.io/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;&#xA;&#xA;&#xA;&lt;p&gt;Here is our description of our presentation at &lt;a href=&#34;%22http://www.brooksbaseball.net/ss18/sunday.html%22&#34;&gt;Saberseminar 2018&lt;/a&gt;: “A common definition of sabermetrics is the application of statistics to baseball. However, despite clear progress over the past few decades, we argue that sabermetrics has largely ignored the most important statistical principle to baseball: generative modeling. In this talk we discuss several conceptual errors with sabermetrics that preclude optimal decision making. Each of these problems can be overcome using a principled Bayesian approach to inference, which we demonstrate using the Stan statistical software.”&lt;/p&gt;</description>
    </item>
    <item>
      <title>Trading Stanton: a modeling sketch</title>
      <link>https://ssp3nc3r.github.io/post/trading-stanton-a-modeling-sketch/</link>
      <pubDate>Fri, 24 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://ssp3nc3r.github.io/post/trading-stanton-a-modeling-sketch/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#forecast-of-giancarlo-stantons-expected-surplus-value&#34;&gt;Forecast of Giancarlo Stanton’s Expected Surplus Value&lt;/a&gt;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#estimate-player-past-performance-as-wins-over-replacement&#34;&gt;Estimate player past performance as Wins Over Replacement&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#forecasting-war-with-a-hierarchical-model-in-stan&#34;&gt;Forecasting WAR with a hierarchical model in Stan&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#dollars-per-war-on-the-free-agent-market&#34;&gt;Dollars Per WAR on the Free-Agent Market&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#unadjusted-surplus-value&#34;&gt;Unadjusted surplus value&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#appendix-stan-model-for-forcasting-war&#34;&gt;Appendix: Stan Model for Forcasting WAR&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div id=&#34;forecast-of-giancarlo-stantons-expected-surplus-value&#34; class=&#34;section level1&#34;&gt;&#xA;&lt;h1&gt;Forecast of Giancarlo Stanton’s Expected Surplus Value&lt;/h1&gt;&#xA;&lt;div id=&#34;summary&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Summary&lt;/h2&gt;&#xA;&lt;p&gt;In most analyses, I would normally lead with the conclusion—here, surplus value. But, as the perceived goals of analysis are evaluating, well, the analysis, I’ll start with my methods. First, I estimate Stanton’s performance in terms of WAR, tying Stanton’s performance to team wins. Then I connect his wins over replacement to dollars. Finally, I subtract out the contract cost and report surplus as net present value.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
